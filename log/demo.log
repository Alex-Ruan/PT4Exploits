Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, beam_size=10, config_name='', data_dir='./data', dev_filename='data_shell_gen_IP/decoder-dev.json.seq2seq', do_eval=True, do_lower_case=False, do_test=True, do_train=True, early_stop_threshold=10, eval_batch_size=4, eval_steps=-1, gradient_accumulation_steps=1, lang='bash', learning_rate=5e-05, load_model_path=None, local_rank=-1, log_name='log/e30-bz4-tokens250-pst3-as-IP-codet5-base.log', loss_filename='loss/e30-bz4-tokens250-pst3-as-IP-codet5-base.csv', max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=128, model_name='/project/ruanxiaoming/codes/models/codet5-base', model_name_or_path=None, model_type=None, no_cuda=False, num_train_epochs=30, output_dir='e30-bz4-tokens250-pst3-as-IP-codet5-base', save_init=False, seed=42, test_filename='data_shell_gen_IP/decoder-test.json.seq2seq', tokenizer_name='', tokens=250, train_batch_size=4, train_filename='data_shell_gen_IP/decoder-train.json.seq2seq', train_steps=-1, visible_gpu='', warm_up_ratio=0.1, weight_decay=0.0)
Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
Model created!!
[[{'text': 'Comment:', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': ' define var0 label', 'loss_ids': 0, 'shortenable_ids': 1}, {'text': ' is the Summarization of:', 'loss_ids': 0, 'shortenable_ids': 0}, {'text': '<mask>', 'loss_ids': 1, 'shortenable_ids': 0}], {'guid': 0, 'tgt_text': 'var0 :'}]
  num_training_steps = 23310
***** Running training *****
  Num examples = 3105
  Batch size = 4
  Num epoch = 30

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 0
  eval_loss = 39.16573
  global_step = 778
  train_loss = 20.6767
  ********************
Previous best ppl:1000000.0
Achieve Best eval_loss:39.16573
  ********************
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 63.68 	 Previous best bleu 0
  ********************
 Achieve Best bleu:63.68
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 1
  eval_loss = 41.83056
  global_step = 1555
  train_loss = 4.4736
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 73.94 	 Previous best bleu 63.68
  ********************
 Achieve Best bleu:73.94
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 2
  eval_loss = 42.7622
  global_step = 2332
  train_loss = 2.5361
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 81.64 	 Previous best bleu 73.94
  ********************
 Achieve Best bleu:81.64
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 3
  eval_loss = 43.50903
  global_step = 3109
  train_loss = 1.7359
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 85.64 	 Previous best bleu 81.64
  ********************
 Achieve Best bleu:85.64
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 4
  eval_loss = 44.83567
  global_step = 3886
  train_loss = 1.2277
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 85.25 	 Previous best bleu 85.64
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 5
  eval_loss = 45.02272
  global_step = 4663
  train_loss = 0.9717
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 86.05 	 Previous best bleu 85.64
  ********************
 Achieve Best bleu:86.05
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 6
  eval_loss = 45.50449
  global_step = 5440
  train_loss = 0.7921
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.07 	 Previous best bleu 86.05
  ********************
 Achieve Best bleu:89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 7
  eval_loss = 46.71625
  global_step = 6217
  train_loss = 0.6763
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 87.57 	 Previous best bleu 89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 8
  eval_loss = 44.79787
  global_step = 6994
  train_loss = 0.6004
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 87.61 	 Previous best bleu 89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 9
  eval_loss = 45.13435
  global_step = 7771
  train_loss = 0.5888
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 87.92 	 Previous best bleu 89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 10
  eval_loss = 45.92201
  global_step = 8548
  train_loss = 0.4974
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 87.38 	 Previous best bleu 89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 11
  eval_loss = 45.43266
  global_step = 9325
  train_loss = 0.4508
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 87.43 	 Previous best bleu 89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 12
  eval_loss = 46.93606
  global_step = 10102
  train_loss = 0.4336
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 87.86 	 Previous best bleu 89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 13
  eval_loss = 46.56283
  global_step = 10879
  train_loss = 0.356
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 86.26 	 Previous best bleu 89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 14
  eval_loss = 46.3255
  global_step = 11656
  train_loss = 0.3151
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 87.8 	 Previous best bleu 89.07
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 15
  eval_loss = 45.55641
  global_step = 12433
  train_loss = 0.3162
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.53 	 Previous best bleu 89.07
  ********************
 Achieve Best bleu:89.53
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 16
  eval_loss = 46.23912
  global_step = 13210
  train_loss = 0.3065
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.16 	 Previous best bleu 89.53
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 17
  eval_loss = 46.84248
  global_step = 13987
  train_loss = 0.2665
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 86.73 	 Previous best bleu 89.53
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 18
  eval_loss = 45.76765
  global_step = 14764
  train_loss = 0.2795
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 88.94 	 Previous best bleu 89.53
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 19
  eval_loss = 45.86284
  global_step = 15541
  train_loss = 0.2342
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.45 	 Previous best bleu 89.53
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 20
  eval_loss = 46.2406
  global_step = 16318
  train_loss = 0.2282
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.91 	 Previous best bleu 89.53
  ********************
 Achieve Best bleu:89.91
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 21
  eval_loss = 45.80775
  global_step = 17095
  train_loss = 0.2067
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.71 	 Previous best bleu 89.91
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 22
  eval_loss = 45.91023
  global_step = 17872
  train_loss = 0.1963
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.31 	 Previous best bleu 89.91
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 23
  eval_loss = 46.47359
  global_step = 18649
  train_loss = 0.2017
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.2 	 Previous best bleu 89.91
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 24
  eval_loss = 47.61997
  global_step = 19426
  train_loss = 0.1854
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.48 	 Previous best bleu 89.91
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 25
  eval_loss = 47.48371
  global_step = 20203
  train_loss = 0.1734
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 90.05 	 Previous best bleu 89.91
  ********************
 Achieve Best bleu:90.05
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 26
  eval_loss = 48.24822
  global_step = 20980
  train_loss = 0.1624
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 89.25 	 Previous best bleu 90.05
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 27
  eval_loss = 48.09984
  global_step = 21757
  train_loss = 0.1597
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 88.84 	 Previous best bleu 90.05
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 28
  eval_loss = 48.29168
  global_step = 22534
  train_loss = 0.1502
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 88.83 	 Previous best bleu 90.05
  ********************

***** Running evaluation *****
  Num examples = 308
  Batch size = 4
  epoch = 29
  eval_loss = 48.25779
  global_step = 23311
  train_loss = 0.1443
  ********************
Previous best ppl:39.16573
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 88.83 	 Previous best bleu 90.05
  ********************
rxm: save train loss file in loss/e30-bz4-tokens250-pst3-as-IP-codet5-base.csv
reload model from e30-bz4-tokens250-pst3-as-IP-codet5-base/checkpoint-best-bleu/pytorch_model.bin
BLEU file: data_shell_gen_IP/decoder-dev.json.seq2seq
  bleu-4 = 90.05 
  ********************
BLEU file: data_shell_gen_IP/decoder-test.json.seq2seq
  bleu-4 = 78.75 
  ********************
Finish training and take 1h51m
